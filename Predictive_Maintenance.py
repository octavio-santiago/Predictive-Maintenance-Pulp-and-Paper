# -*- coding: utf-8 -*-
"""

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ivjZ_gODG74kPBSCuTnopLplWVh2yoa7

# Importing libs and Loading datasets
"""

# Commented out IPython magic to ensure Python compatibility.
from google.colab import drive
drive.mount('/gdrive')
# %cd /gdrive

!pip install lifelines

!pip install shap

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import random

from sklearn import preprocessing
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.feature_selection import VarianceThreshold

from sklearn.ensemble import IsolationForest
from sklearn.ensemble import RandomForestRegressor
from sklearn.neighbors import LocalOutlierFactor
from sklearn.decomposition import PCA
from sklearn import svm
import xgboost as xgb

from sklearn.metrics import roc_curve, precision_recall_curve, auc,mean_squared_error, r2_score, classification_report, confusion_matrix
from scipy.stats.stats import pearsonr

import shap

from lifelines import KaplanMeierFitter

root_path = "/gdrive/My Drive"
columns = ["asset_id","runtime","setting1","setting2","setting3"]

if len(columns) == 5:
  for i in range(1,22):
    columns.append(f"tag{i}")

df = pd.read_table(f"{root_path}/PM_train.txt", delimiter=" ", sep = "\t", header=None)

df = df.iloc[:,:len(columns)]
df.columns=columns

df_test =  pd.read_table(f"{root_path}/PM_test.txt", delimiter=" ", sep = "\t", header=None)
df_test = df_test.iloc[:,:len(columns)]
df_test.columns=columns

"""# Functions"""

def get_time(row,df_tr):
  '''Get the Remaining Time based in the actual Runtime and the Maximum Runtime 
  for each asset'''
  id = row['asset_id']
  day = row['runtime']
  max_days = df_tr.loc[id]
  rem_day = max_days - day
  return rem_day

def simulate_scenarios(df, test_list, y_pred):
  '''Simulate scenarios with Classification Metrics based in the Business Rules
  '''
  df_sim = df.copy()
  df_sim['target'] = df_sim['runtime'].apply(lambda x: 1 if x <= 20 else 0)

  y_true = df_sim[df_sim['asset_id'].isin(test_list)]['time_rem'].apply(lambda x: 1 if x <= 20 else 0)
  print("Size y_true: ", len(y_true))
  if type(y_pred) != type(pd.DataFrame()):
    y_pred = pd.Series(y_pred)
    y_pred = y_pred.apply(lambda x: 1 if x <= 20 else 0)
  else:
    y_pred = y_pred.apply(lambda x: 1 if x <= 20 else 0)

  print("Size y_pred: ", len(y_pred))
  print(classification_report(y_true, y_pred))
  print("Confusion Matrix")
  print(confusion_matrix(y_true, y_pred))

#train, test sep
def preproc(df, test_list=[2,13,20,30,31,59,73,90,95,100], deep=False, debug=True): 
  ''' Pre process function for timeseries RUL models.
  It takes the raw dataset and a list of assets for test and:
  - Separates X,y for Train and Test
  - remove low var variables
  - scale variables
   '''

  X_train = df[~df['asset_id'].isin(test_list)].drop(columns=['asset_id'])
  X_test = df[df['asset_id'].isin(test_list)].drop(columns=['asset_id'])

  y_train = y[~y['asset_id'].isin(test_list)]['time_rem']
  y_test = y[y['asset_id'].isin(test_list)]['time_rem']

  #feature selection - remove low var variables
  cols = list(X_train.columns)
  std = X_train.std()

  relevant_features = std[std > 0.000001]

  features = [x for x in list(relevant_features.index) if x not in ['tag6','tag9','tag14','setting1','setting2']]

  if debug:
    print("Features after remove non-var features")
    print(relevant_features)
    print(features)
    print("Features before selection: ", len(list(X_train.columns)))
    print("Features after selection ", len(features))

  X_train = X_train[features]
  X_test = X_test[features]

  #scaling
  if deep:
    scaler = MinMaxScaler()
    X_train[features] = scaler.fit_transform(X_train[features])
    X_test[features] = scaler.transform(X_test[features])

  else:
    scaler = StandardScaler()
    X_train[features] = scaler.fit_transform(X_train[features])
    X_test[features] = scaler.transform(X_test[features])

  return X_train,y_train,X_test,y_test,features,scaler

def time_series_fold(n,df,model,deep=False):
  '''Creates a Timeseries RUL cross validation k-folds method'''
  rmse_list_t = []
  mae_list_t = []

  rmse_list = []
  mae_list = []

  possible_list = [x for x in range(1,100)]

  for i in range(0,n-1):
    test_list = []
    for i in range(1,n+1):
      if len(possible_list) > 1:
        val = possible_list[random.randint(0, len(possible_list)-1)]
      elif len(possible_list) == 1:
        val = possible_list[0]

      test_list.append(val)
      possible_list.remove(val)
      
    X_train,y_train,X_test,y_test,features = preproc(df, test_list=test_list, deep=deep, debug=False)

    if deep:

        early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)

        EPOCHS = 1000

        history = model.fit(
          X_train, y_train,
          epochs=EPOCHS, validation_split = 0.2, verbose=0,
          callbacks=[early_stop])
    else:
      model.fit(X_train,y_train)

    metrics = evaluate(X_train, X_test, y_train, y_test, model, debug=False)

    rmse_list_t.append(metrics['train_rmse'])
    mae_list_t.append(metrics['train_mae'])

    rmse_list.append(metrics['test_rmse'])
    mae_list.append(metrics['test_mae'])

  print(f"Cross Validation {n} folds")
  print("----------Train-----------")
  print("RMSE Mean: ", np.mean(rmse_list_t), "+- ", np.std(rmse_list_t) )
  print("MAE Mean: ", np.mean(mae_list_t), "+- ", np.std(mae_list_t) )

  print("----------Test-----------")
  print("RMSE Mean: ", np.mean(rmse_list), "+- ", np.std(rmse_list) )
  print("MAE Mean: ", np.mean(mae_list), "+- ", np.std(mae_list) )

#model evaluation

def mean_absolute_percentage_error(y_true, y_pred):
  y_true, y_pred = np.array(y_true), np.array(y_pred)
  return np.mean(np.abs((y_true - y_pred) / y_true)) * 100

def mean_absolute_error(y_true, y_pred):
  y_true, y_pred = np.array(y_true), np.array(y_pred)
  return np.mean(np.abs(y_true - y_pred))

def evaluate(X_train, X_test, y_train, y_test, model, debug = True, deep=False):
  '''Function that evaluate ML models with regression metrics '''

  y_true = y_train
  if deep:
    y_pred = model.predict(X_train).flatten()
  else:
    y_pred = model.predict(X_train)

  mae_t = mean_absolute_error(y_true, y_pred)
  mape = mean_absolute_percentage_error(y_true, y_pred)
  rmse_t = np.sqrt(mean_squared_error(y_true, y_pred))
  try:
    corr = pearsonr(y_true,y_pred)[0]
  except:
    corr = 0
  if debug:
    print('--------Train-------')
    print("r squared: " + format(r2_score(y_true, y_pred), '.2f'))
    print("MAE: " + format(mae_t, '.3f'))
    print("MAPE: " + format(mape, '.3f'))
    print("RMSE: %f" % (rmse_t))
    print("Correlation: " + format(corr, '.2f'))
  
  
  y_true = y_test
  if deep:
    y_pred = model.predict(X_test).flatten()
  else:
    y_pred = model.predict(X_test)
    
  mae_e = mean_absolute_error(y_true, y_pred)
  mape = mean_absolute_percentage_error(y_true, y_pred)
  rmse_e = np.sqrt(mean_squared_error(y_true, y_pred))
  try:
    corr = pearsonr(y_true,y_pred)[0]
  except:
    corr = 0

  if debug:
    print('--------Test-------')
    print("r squared: " + format(r2_score(y_true, y_pred), '.2f'))
    print("MAE: " + format(mae_e, '.3f'))
    print("MAPE: " + format(mape, '.3f'))
    print("RMSE: %f" % (rmse_e))
    print("Correlation: " + format(corr, '.2f'))

  return {'train_rmse': rmse_t, 'test_rmse': rmse_e , 
          'train_mae': mae_t, 'test_mae': mae_e
          }

def evaluate_graphs(df,X_train, X_test, y_train, y_test, model, features, deep=False):
  '''Function that plots evaluation graphs for RUL models '''
  y_true = y_train
  if deep:
    y_pred = model.predict(X_train).flatten()
  else:
    y_pred = model.predict(X_train)
  
  print('Train fit ')
  #y_pred = xg_reg.predict(df[df['asset_id'] == val].drop(columns=['asset_id']))
  plt.figure(figsize=(30, 8))
  plt.plot(X_train.reset_index().iloc[:,0],y_train, 'c--', linewidth=3)
  plt.plot(X_train.reset_index().iloc[:,0],y_pred, color='orange')
  plt.show()
  print(" ")

  print('Test fit ')
  #Test
  y_true = y_test
  if deep:
    y_pred = model.predict(X_test).flatten()
  else:
    y_pred = model.predict(X_test)

  for val in test_list:
    print(f"Asset {val}")
    print(" ")
    indexes = list(df[df['asset_id'] == val].index)

    #y_pred = model.predict(df[df['asset_id'] == val][features])
    y_pred = model.predict(X_test[X_test.index.isin(indexes)])

    df_eval = df[df['asset_id'] == val]
    #plt.bar(df_eval['runtime'],y[y['asset_id'] == val]['time_rem'])
    plt.plot(df_eval['runtime'],y[y['asset_id'] == val]['time_rem'], 'c--', linewidth=3)
    plt.plot(df_eval['runtime'],y_pred, color='orange')
    plt.show()

"""# Estatistical Data Analysis"""

df.head()

df.describe()

# stats for failure
df_tr = df[['asset_id','runtime']].groupby('asset_id').runtime.max()
df_tr.describe()

pd.plotting.scatter_matrix(df, figsize=(20, 20))
plt.show()

cor = df.corr()
plt.figure(figsize=(30, 10))
sns.heatmap(cor, annot=True, cmap=plt.cm.Reds)
plt.show()

#time remaning calc - creating the target
df_tr = df[['asset_id','runtime']].groupby('asset_id').runtime.max()

y = df[['asset_id','runtime']]
y['time_rem'] = df[['asset_id','runtime']].apply(lambda row: get_time(row, df_tr), axis=1)

#list for testing
test_list=[2,13,20,30,31,59,73,90,95,100]

df_anali = df.copy()
df_anali['time_rem'] = y['time_rem']
df_anali['color'] = df_anali['time_rem'].apply(lambda x: 'r' if x <= 20 else 'b')

col_list = [ x for x in list(df_anali.columns) if x not in ['asset_id','color','runtime','time_rem']]

for c in col_list:
  print(c.upper())
  print(" ")
  temp = df_anali[['runtime',c,'color']]
  #sns.scatterplot(data=temp, x="runtime", y=c, hue="color")
  plt.scatter(temp['runtime'] , temp[c] , c= temp['color'], alpha=0.5, s=4)
  plt.show()
  try:
    sns.kdeplot(data=temp, x=c, hue="color",fill=True, common_norm=False,alpha=.5, linewidth=0)
    plt.show()
  except:
    pass

test_list=[2,13,20]
plt.figure(figsize=(30, 10))
sns.barplot(data=y[y['asset_id'].isin(test_list)].reset_index(), x="index", y="time_rem", hue="asset_id")

"""# Kaplan Meier - Baseline RUL """

df_train = df[['asset_id','runtime']].groupby('asset_id').runtime.max().reset_index()

kmf = KaplanMeierFitter()
T = df['runtime']
kmf.fit(T)

#chance to be alive
kmf.plot()

median_survival = kmf.median_survival_time_
maint = median_survival - 20
print(f'Median survival time is : {median_survival} cycles')
print(f'Baseline for a fixed value that Maintenance can use: {maint} cycles')

kmf.survival_function_
kmf.confidence_interval_

conditional_time = kmf.conditional_time_to_event_

df_test_kmf = df_test[['asset_id','runtime']].groupby('asset_id').runtime.max().reset_index()

kmf.survival_function_at_times(df_test_kmf['runtime'])

df_test_baseline = df_test[['asset_id','runtime']]
df_test_baseline['predictions'] = df_test_baseline['runtime'].apply(lambda x: conditional_time.loc[x])
df_test_baseline

#simulate for a fixed time - RUL baseline
test_list=[2,13,20,30,31,59,73,90,95,100]

y_true = y[y['asset_id'].isin(test_list)]['time_rem'].apply(lambda x: 1 if x <= 20 else 0)
y_pred = y[y['asset_id'].isin(test_list)]['runtime'].apply(lambda x: 1 if x >= maint else 0)

print(classification_report(y_true, y_pred))
print("Confusion Matrix")
print(confusion_matrix(y_true, y_pred))

"""## RUL Model Predict

"""

test_list=[2,13,20,30,31,59,73,90,95,100]

X_train = df[~df['asset_id'].isin(test_list)]
X_test = df[df['asset_id'].isin(test_list)]

y_train = y[~y['asset_id'].isin(test_list)]['time_rem']
y_test = y[y['asset_id'].isin(test_list)]['time_rem']

T = X_train['runtime']
kmf.fit(T)
kmf.plot()
median_survival = kmf.median_survival_time_
print(median_survival)

#evaluate
def mean_absolute_error(y_true, y_pred):
  y_true, y_pred = np.array(y_true), np.array(y_pred)
  return np.mean(np.abs(y_true - y_pred))
#train
conditional_time = kmf.conditional_time_to_event_
df_train_baseline = X_train[['asset_id','runtime']]
df_train_baseline['predictions'] = df_train_baseline['runtime'].apply(lambda x: conditional_time.loc[x])

print("------Train------")
rmse = np.sqrt(mean_squared_error(y_train, df_train_baseline['predictions']))
mae = mean_absolute_error(y_train, df_train_baseline['predictions'])
corr = pearsonr(y_train, df_train_baseline['predictions'])[0]
print("RMSE: %f" % (rmse))
print("MAE: %f" % (mae))
print(f"Correlation: {corr}")


#test
conditional_time = kmf.conditional_time_to_event_
df_test_baseline = X_test[['asset_id','runtime']]
df_test_baseline['predictions'] = df_test_baseline['runtime'].apply(lambda x: conditional_time.loc[x])

print("------Test------")
rmse = np.sqrt(mean_squared_error(y_test, df_test_baseline['predictions']))
mae = mean_absolute_error(y_test, df_test_baseline['predictions'])
corr = pearsonr(y_test, df_test_baseline['predictions'])[0]
print("RMSE: %f" % (rmse))
print("MAE: %f" % (mae))
print(f"Correlation: {corr}")

y_pred = df_test_baseline['predictions']

simulate_scenarios(y, test_list, y_pred)



"""# Machine Learning Methods"""

X_train,y_train,X_test,y_test,features = preproc(df, deep=False)

"""# XGBoosting"""

X_train,y_train,X_test,y_test,features, scaler = preproc(df, deep=False)

xg_reg = xgb.XGBRegressor(objective ='reg:tweedie', tweedie_variance_power = 1.2 ,colsample_bytree = 0.3, learning_rate = 0.1,
                max_depth = 5)

xg_reg.fit(X_train,y_train)

preds = xg_reg.predict(X_test)

metrics = evaluate(X_train, X_test, y_train, y_test, xg_reg)

simulate_scenarios(y, test_list, preds)

#Correlation
#train
y_true = y_train
y_pred = xg_reg.predict(X_train)
plt.scatter(y_true,y_pred)
#Test
y_true = y_test
y_pred = xg_reg.predict(X_test)
plt.scatter(y_true,y_pred)

time_series_fold(10,df,xg_reg)

evaluate_graphs(df,X_train, X_test, y_train, y_test, xg_reg,features)

#Grid Search
df_grid = pd.DataFrame()
k_list = ['reg:tweedie','reg:squarederror','reg:gamma']
k_list = [1.3,1.35,1.4,1.5]
n_list = [50,100,150,200]

for n in n_list:
  for k in k_list:
    #print(f"Running for n = {n} and k = {k}")

    xg_reg = xgb.XGBRegressor(objective='reg:tweedie' , tweedie_variance_power = k , learning_rate = 0.1, max_depth = 6, n_estimators = n, booster='gbtree')
    xg_reg.fit(X_train,y_train)
    metrics = evaluate(X_train, X_test, y_train, y_test, xg_reg, debug=False)

    df_grid = df_grid.append(pd.DataFrame({'n_vals':[n], 'k_vals':[k], 'train_rmse': [metrics['train_rmse']], 'test_rmse': [metrics['test_rmse']] }), ignore_index=True)
    #print(" ")

print(df_grid)

sns.lineplot(data=df_grid, x="k_vals", y="train_rmse", hue="n_vals")
#plt.show()
sns.lineplot(data=df_grid, x="k_vals", y="test_rmse", hue="n_vals")
#plt.show()

#reg:squarederror: regression with squared loss.
#reg:gamma: gamma regression with log-link. Output is a mean of gamma distribution. It might be useful, e.g., for modeling insurance claims severity, or for any outcome that might be gamma-distributed.
#reg:tweedie: Tweedie regression with log-link. It might be useful, e.g., for modeling total loss in insurance, or for any outcome that might be Tweedie-distributed.

"""# Random Forest"""

X_train,y_train,X_test,y_test,features,scaler = preproc(df, deep=False)

rfr = RandomForestRegressor(n_estimators = 50, criterion = 'mse', max_depth = 9, max_features='auto')

rfr.fit(X_train,y_train)

metrics = evaluate(X_train, X_test, y_train, y_test, rfr)

simulate_scenarios(y, test_list, rfr.predict(X_test))

time_series_fold(10,df,rfr)

evaluate_graphs(df,X_train, X_test, y_train, y_test, rfr, features)

#Grid Search
df_grid = pd.DataFrame()
k_list = [7,8,9,10]
n_list = [5,10,50]

for n in n_list:
  for k in k_list:
    #print(f"Running for n = {n} and k = {k}")

    rfr = RandomForestRegressor(n_estimators = n, criterion = 'mse', max_depth = k, max_features='auto')
    rfr.fit(X_train,y_train)
    metrics = evaluate(X_train, X_test, y_train, y_test, rfr, debug=False)

    df_grid = df_grid.append(pd.DataFrame({'n_vals':[n], 'k_vals':[k], 'train_rmse': [metrics['train_rmse']], 'test_rmse': [metrics['test_rmse']] }), ignore_index=True)
    #print(" ")

print(df_grid)

sns.lineplot(data=df_grid, x="k_vals", y="train_rmse", hue="n_vals")
sns.lineplot(data=df_grid, x="k_vals", y="test_rmse", hue="n_vals")

"""# SVM"""

X_train,y_train,X_test,y_test,features, scaler = preproc(df, deep=False)

#svr = svm.SVR().fit(X_train,y_train)
svr_rbf = svm.SVR(kernel='rbf', C=100, gamma=0.1, epsilon=.1).fit(X_train,y_train)
#svr_lin = svm.SVR(kernel='linear', C=100, gamma='auto').fit(X_train,y_train)
#svr_poly = svm.SVR(kernel='poly', C=100, gamma='auto', degree=3, epsilon=.1,coef0=1).fit(X_train,y_train)

#metrics = evaluate(X_train, X_test, y_train, y_test, svr)

evaluate(X_train, X_test, y_train, y_test, svr_rbf)
#evaluate(X_train, X_test, y_train, y_test, svr_lin)
#evaluate(X_train, X_test, y_train, y_test, svr_poly)

simulate_scenarios(y, test_list, svr_rbf.predict(X_test))

evaluate_graphs(df,X_train, X_test, y_train, y_test, svr_rbf, features)

"""# Deep Learning"""

import tensorflow as tf
from tensorflow import keras
from keras import layers
from keras.models import Sequential
from keras.layers import Dense
from keras.wrappers.scikit_learn import KerasRegressor

def build_model():
  model = keras.Sequential([
    layers.Dense(16, activation='relu', input_shape=[len(X_train.keys())]),
    #layers.Dense(16, activation='relu'),
    layers.Dense(1)
  ])

  optimizer = tf.keras.optimizers.RMSprop(0.001)

  model.compile(loss='mse',
                optimizer=optimizer,
                metrics=['mae', 'mse'])
  return model

model = build_model()

model.summary()

# Mostra o progresso do treinamento imprimindo um único ponto para cada epoch completada
class PrintDot(keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs):
    if epoch % 100 == 0: print('')
    print('.', end='')

early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)

EPOCHS = 1000

history = model.fit(
  X_train, y_train,
  epochs=EPOCHS, validation_split = 0.2, verbose=0,
  callbacks=[early_stop, PrintDot()])

hist = pd.DataFrame(history.history)
hist['epoch'] = history.epoch
hist.tail()

def plot_history(history):
  hist = pd.DataFrame(history.history)
  hist['epoch'] = history.epoch

  plt.figure()
  plt.xlabel('Epoch')
  plt.ylabel('Mean Abs Error [MPG]')
  plt.plot(hist['epoch'], hist['mae'],
           label='Train Error')
  plt.plot(hist['epoch'], hist['val_mae'],
           label = 'Val Error')
  #plt.ylim([0,5])
  plt.legend()

  plt.figure()
  plt.xlabel('Epoch')
  plt.ylabel('Mean Square Error [$MPG^2$]')
  plt.plot(hist['epoch'], hist['mse'],
           label='Train Error')
  plt.plot(hist['epoch'], hist['val_mse'],
           label = 'Val Error')
  #plt.ylim([0,20])
  plt.legend()
  plt.show()


plot_history(history)

metrics = evaluate(X_train, X_test, y_train, y_test, model, deep=True)

time_series_fold(10,df,model, deep=True)

simulate_scenarios(y, test_list, model.predict(X_test).flatten())

evaluate_graphs(df,X_train, X_test, y_train, y_test, model, features, deep=True)

"""# Feature Importance

"""

explainer = shap.TreeExplainer(rfr)
shap_values = explainer.shap_values(X_train)

shap.summary_plot(shap_values, X_train)

explainer = shap.TreeExplainer(xg_reg)
shap_values = explainer.shap_values(X_train)
shap.summary_plot(shap_values, X_train)

xgb.plot_importance(xg_reg)

shap.force_plot(explainer.expected_value, shap_values[0,:], X_train.iloc[0,:])

for name in X_train.columns:
    shap.dependence_plot(name, shap_values, X_train, display_features=X_train)

explainer = shap.TreeExplainer(rfr)
shap_values = explainer.shap_values(X_test)
shap.summary_plot(shap_values, X_test)

"""Notations
-------

* Lag features - use setpoint to lag
* Calculate time to run and plot results x time_to_run
* Use of Sklearn pipeline - adapt code

# Predict Validation Set
"""

df_test.describe()

features = list(X_test.columns)
print(features)

pd.plotting.scatter_matrix(df_test[features], figsize=(20, 20))
plt.show()

X_valid = df_test[features]
X_valid = scaler.transform(X_valid)

y_pred = rfr.predict(X_valid)

df_pred = pd.DataFrame({'predicted': y_pred})
df_pred

plt.figure(figsize=(30, 10))
#plt.plot(df_test.index ,df_test.runtime, 'c--', linewidth=3)
plt.plot(df_test.index ,df_pred.predicted, 'c--', linewidth=3)
plt.bar(df_pred.index ,df_pred.predicted, color='orange')
plt.show()

#save predictions
df_pred.to_csv('/gdrive/My Drive/regressao_octavio_santiago.csv', index = False)
